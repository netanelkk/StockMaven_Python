{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "ozQm6lfqcSUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "WlGcnyUMjr_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAHXQfYO5tjh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "from pandas_datareader import DataReader\n",
        "import pandas_datareader as dr\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "%matplotlib inline\n",
        "\n",
        "# For reading stock data from yahoo\n",
        "from pandas_datareader.data import DataReader\n",
        "import yfinance as yf\n",
        "\n",
        "# For time stamps\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "qh-qOniRkyqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X42E-WiGe2vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfDerJlS50BX"
      },
      "outputs": [],
      "source": [
        "start_date = datetime(2010, 1, 1)\n",
        "end_date = datetime(2023, 4, 5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_list =[\n",
        "  'AAPL',  'META',   'MSFT', 'GOOG', 'NKE',\n",
        "  'NFLX',  'ADBE',   'ZM',   'NVDA', 'HUBS',\n",
        "  'LH',    'ET',     'KBR',  'WMT',  'SYK',\n",
        "  'DE',    'APLS',   'HD',   'JBL',  'PSTG',\n",
        "  'PANW',  'SQ',     'PPL',  'ACGL', 'DDOG',\n",
        "  'GOOGL', 'ALV.DE', 'PZZA', 'STEM', 'GE',\n",
        "  'GM',    'SITM',   'BOX',  'SGEN', 'CTVA',\n",
        "  'DT',    'PLNT',   'GTLS', 'PRVA', 'DG.PA',\n",
        "  'PINS',  'CVE',    'VMC',  'GLOB', 'CPA',\n",
        "  'FTI',   'AEM',    'WCN'\n",
        "]\n",
        "for stock in stocks_list:\n",
        "    globals()[stock] = yf.download(stock, start_date, end_date)"
      ],
      "metadata": {
        "id": "9qJSELkjjp9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company_list =[\n",
        "  'AAPL',  'META',   'MSFT', 'GOOG', 'NKE',\n",
        "  'NFLX',  'ADBE',   'ZM',   'NVDA', 'HUBS',\n",
        "  'LH',    'ET',     'KBR',  'WMT',  'SYK',\n",
        "  'DE',    'APLS',   'HD',   'JBL',  'PSTG',\n",
        "  'PANW',  'SQ',     'PPL',  'ACGL', 'DDOG',\n",
        "  'GOOGL', 'ALV.DE', 'PZZA', 'STEM', 'GE',\n",
        "  'GM',    'SITM',   'BOX',  'SGEN', 'CTVA',\n",
        "  'DT',    'PLNT',   'GTLS', 'PRVA', 'DG.PA',\n",
        "  'PINS',  'CVE',    'VMC',  'GLOB', 'CPA',\n",
        "  'FTI',   'AEM',    'WCN'\n",
        "]\n",
        "\n",
        "company_name = [\n",
        "  'Apple Inc.',       'Meta',             'Microsoft',\n",
        "  'Google',           'Nike',             'Netflix',\n",
        "  'Adobe',            'Zoom Inc.',        'Nvidia',\n",
        "  'HubSpot',          'Laboratory Corp',  'Energy Transfer',\n",
        "  'KBR Inc',          'Walmart Inc.',     'Stryker Corp',\n",
        "  'Deere & Co',       'Apellis',          'Home Depot Inc.',\n",
        "  'Jabil Inc.',       'Pure Storage',     'Palo Alto',\n",
        "  'Block Inc.',       'PPL Corp',         'Arch Capital',\n",
        "  'Datadog Inc.',     'Alphabet Inc.',    'Allianz SE',\n",
        "  \"Papa John's\",      'Stem Inc.',        'General Electric',\n",
        "  'General Motors',   'SiTime Corp.',     'Box Inc.',\n",
        "  'Seagen Inc.',      'Corteva Inc.',     'Dynatrace Inc.',\n",
        "  'Planet Fitness',   'Chart Industries', 'Privia Health',\n",
        "  'Vinci S.A',        'Pinterest',        'Cenovus Energy',\n",
        "  'Vulcan Materials', 'Globant SA',       'Copa Holdings',\n",
        "  'TechnipFMC',       'Agnico Eagle',     'Waste Conn.'\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for company, com_name in zip(company_list, company_name):\n",
        "    company_df = globals()[company] # retrieve the corresponding dataframe\n",
        "    company_df[\"company_name\"] = com_name # assign the com_name variable to the company_name column of the dataframe\n",
        "    df_list.append(company_df)\n",
        "\n",
        "df = pd.concat(df_list, axis=0)\n",
        "df.tail(10)"
      ],
      "metadata": {
        "id": "yPDaXL28ozuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def save_volume_min_max_to_json(df, filename):\n",
        "    grouped = df.groupby('company_name')\n",
        "\n",
        "    volume_min_max_dict = {}\n",
        "\n",
        "    for company, group in grouped:\n",
        "        volume_min_max_dict[company] = {\n",
        "            'min_volume': float(group['Volume'].min()),\n",
        "            'max_volume': float(group['Volume'].max())\n",
        "        }\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(volume_min_max_dict, f)\n"
      ],
      "metadata": {
        "id": "n0e7Vzx0sDQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_volume_min_max_to_json(df, 'stocks_volume_min_max.json')"
      ],
      "metadata": {
        "id": "desJHERHsWzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "t3H1bWTVo7z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCRrgp3c58rT"
      },
      "outputs": [],
      "source": [
        "snoppi_stocks = ['^GSPC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsnAvFiP6FV9"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "\n",
        "df_snopi = yf.download(snoppi_stocks, start_date, end_date, group_by='column')\n",
        "df_snopi\n",
        "df_snopi.reset_index(level=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSWa5A7T6NcO"
      },
      "outputs": [],
      "source": [
        "vix_stock = ['^VIX']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMSiBna86Tuo"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "\n",
        "df_vix = yf.download(vix_stock, start_date, end_date, group_by='column')\n",
        "df_vix\n",
        "df_vix.reset_index(level=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4JanJtG7k-u"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T76OXDFaMGjW"
      },
      "outputs": [],
      "source": [
        "# df_apple.rename(columns = {'Open':'Open_appl','High':'High_appl','Low':'Low_appl','Close':'Close_appl','Adj Close':'Adj Close_appl','Volume':'Volume_appl'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "746-WoJpOVC5"
      },
      "outputs": [],
      "source": [
        "# df_apple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df_snopi.index[1:]:\n",
        "    df_snopi.at[i,\"GSPC_change_in_day_Adj\"] = ((df_snopi.at[i-1,\"Adj Close\"] - df_snopi.at[i-1,\"Open\"]) / df_snopi.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_snopi.at[i,\"GSPC_change_in_day\"] = ((df_snopi.at[i-1,\"Close\"] - df_snopi.at[i-1,\"Open\"]) / df_snopi.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_snopi.at[i,\"GSPC_change_in_day_open_high\"] = ((df_snopi.at[i-1,\"Open\"] - df_snopi.at[i-1,\"High\"]) / df_snopi.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_snopi.at[i,\"GSPC_change_in_day_open_low\"] = ((df_snopi.at[i-1,\"Open\"] - df_snopi.at[i-1,\"Low\"]) / df_snopi.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_snopi.at[i,\"GSPC_change_in_day_high_low\"] = ((df_snopi.at[i-1,\"High\"] - df_snopi.at[i-1,\"Low\"]) / df_snopi.at[i-1,\"Adj Close\"]) * 100"
      ],
      "metadata": {
        "id": "p1YQg4_MaLfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGFz3usxMegP"
      },
      "outputs": [],
      "source": [
        "df_snopi.rename(columns = {'Open':'Open_GSPC','High':'High_GSPC','Low':'Low_GSPC','Close':'Close_GSPC','Adj Close':'Adj Close_GSPC','Volume':'Volume_GSPC'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kSoJlf07mrR"
      },
      "outputs": [],
      "source": [
        "df_snopi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df_vix.index[1:]:\n",
        "    df_vix.at[i,\"VIX_change_in_day_Adj\"] = ((df_vix.at[i-1,\"Adj Close\"] - df_vix.at[i-1,\"Open\"]) / df_vix.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_vix.at[i,\"VIX_change_in_day\"] = ((df_vix.at[i-1,\"Close\"] - df_vix.at[i-1,\"Open\"]) / df_vix.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_vix.at[i,\"VIX_change_in_day_open_high\"] = ((df_vix.at[i-1,\"Open\"] - df_vix.at[i-1,\"High\"]) / df_vix.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_vix.at[i,\"VIX_change_in_day_open_low\"] = ((df_vix.at[i-1,\"Open\"] - df_vix.at[i-1,\"Low\"]) / df_vix.at[i-1,\"Adj Close\"]) * 100\n",
        "    df_vix.at[i,\"VIX_change_in_day_high_low\"] = ((df_vix.at[i-1,\"High\"] - df_vix.at[i-1,\"Low\"]) / df_vix.at[i-1,\"Adj Close\"]) * 100"
      ],
      "metadata": {
        "id": "-X3HMigOZ4wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQx6-sWn7tYY"
      },
      "outputs": [],
      "source": [
        "df_vix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9I49uJ8PMFm"
      },
      "outputs": [],
      "source": [
        "df_vix.rename(columns = {'Open':'Open_VIX','High':'High_VIX','Low':'Low_VIX','Close':'Close_VIX','Adj Close':'Adj Close_VIX','Volume':'Volume_VIX'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5UH7poSPcDp"
      },
      "outputs": [],
      "source": [
        "df_vix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAB64-VjRKYZ"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(df,df_snopi,on='Date')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "BNlaMNZesJyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF01KQoJSf1o"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(df,df_vix,on='Date')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SCRNXNfuseyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writer = pd.ExcelWriter('output_before_sort.xlsx')\n",
        "\n",
        "# # write the dataframe to a sheet called 'Sheet1'\n",
        "# df.to_excel(writer, sheet_name='Sheet1')\n",
        "\n",
        "# # save the excel file\n",
        "# writer.save()"
      ],
      "metadata": {
        "id": "1QsFxhEml_4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8udkRfiSq7M"
      },
      "outputs": [],
      "source": [
        "df.drop(\"Volume_VIX\",axis='columns',inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "G1KI6-N7n7bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values([\"company_name\", \"Date\"], ascending=[True, False]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "6KGS0pDb0J_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnUgdkYVTYRP"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.index[1:]:\n",
        "  if df.at[i,\"company_name\"] == df.at[i-1,\"company_name\"]:\n",
        "    df.at[i,\"stock_change_target\"] = ((df.at[i-1,\"Adj Close\"] - df.at[i,\"Adj Close\"]) / df.at[i-1,\"Adj Close\"]) * 100\n",
        "    df.at[i,\"stock_change_in_day_Adj\"] = ((df.at[i-1,\"Adj Close\"] - df.at[i-1,\"Open\"]) / df.at[i-1,\"Adj Close\"]) * 100\n",
        "    df.at[i,\"stock_change_in_day\"] = ((df.at[i-1,\"Close\"] - df.at[i-1,\"Open\"]) / df.at[i-1,\"Adj Close\"]) * 100\n",
        "    df.at[i,\"stock_change_in_day_open_high\"] = ((df.at[i-1,\"Open\"] - df.at[i-1,\"High\"]) / df.at[i-1,\"Adj Close\"]) * 100\n",
        "    df.at[i,\"stock_change_in_day_open_low\"] = ((df.at[i-1,\"Open\"] - df.at[i-1,\"Low\"]) / df.at[i-1,\"Adj Close\"]) * 100\n",
        "    df.at[i,\"stock_change_in_day_high_low\"] = ((df.at[i-1,\"High\"] - df.at[i-1,\"Low\"]) / df.at[i-1,\"Adj Close\"]) * 100\n"
      ],
      "metadata": {
        "id": "m-3X3zq91y9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writer = pd.ExcelWriter('output.xlsx')\n",
        "\n",
        "# # write the dataframe to a sheet called 'Sheet1'\n",
        "# df.to_excel(writer, sheet_name='Sheet1')\n",
        "\n",
        "# # save the excel file\n",
        "# writer.save()"
      ],
      "metadata": {
        "id": "Y3kR1Qlg3htz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "wHe8I6enpKBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "vyBDXhguVt7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby('company_name')\n",
        "\n",
        "# Define the min-max normalization function\n",
        "def min_max_normalize(x):\n",
        "    return (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "# Apply the min-max normalization function to the Volume column for each group\n",
        "df['Volume_normalized'] = grouped['Volume'].apply(min_max_normalize)"
      ],
      "metadata": {
        "id": "_UuQyLz0Wf1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df['Volume_GSPC_normalized'] = scaler.fit_transform(df[['Volume_GSPC']])"
      ],
      "metadata": {
        "id": "aPstM4xKbnN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "qeBYU2qGXA3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "2U0a7Arekhnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma_day = [10, 20, 50]\n",
        "\n",
        "for ma in ma_day:\n",
        "    column_name = f\"stock_MA_for_{ma}_days\"\n",
        "    df[column_name] = df['stock_change_target'].rolling(ma).mean()"
      ],
      "metadata": {
        "id": "nVZvAd7uqI5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma_day = [10, 20, 50]\n",
        "\n",
        "for ma in ma_day:\n",
        "    column_name = f\"GSPC_MA_for_{ma}_days\"\n",
        "    df[column_name] = df['GSPC_change_in_day_Adj'].rolling(ma).mean()"
      ],
      "metadata": {
        "id": "wMlNjE7IqIyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma_day = [10, 20, 50]\n",
        "\n",
        "for i in ma_day:\n",
        "    column_name = f\"VIX_MA_for_{ma}_days\"\n",
        "    df[column_name] = df['VIX_change_in_day_Adj'].rolling(ma).mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "y2oBE6q2qIjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "# end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "# df['Adj Close_appl'].plot(figsize=(18,7),legend=True,color='#fc03f4')\n",
        "# plt.ylabel('Price')\n",
        "# plt.xlabel('date')\n",
        "# plt.title('Apple Stock Adj Close Price' + start_date_str + '-' + end_date_str);"
      ],
      "metadata": {
        "id": "-6Gd9m-gSLCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# df_apple_full[['Adj Close_appl', \"apple MA for 10 days\", \"apple MA for 20 days\", \"apple MA for 50 days\"]].plot(figsize=(18,7),legend=True)\n",
        "# plt.ylabel('Price')\n",
        "# plt.xlabel('date')\n",
        "# plt.title('Apple Stock Adj Close Price' + start_date_str + '-' + end_date_str);"
      ],
      "metadata": {
        "id": "-DyW0yjkNcNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_apple_full['Volume_appl'].plot(figsize=(18,7),legend=True,color=('#03874b'))\n",
        "# plt.ylabel('Volume')\n",
        "# plt.title('Apple Stock Volume' + start_date_str + '-' + end_date_str);"
      ],
      "metadata": {
        "id": "wf2XF4Q_Sylm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_traces(go.Heatmap(\n",
        "    z=df.corr(),\n",
        "    x= df.columns,\n",
        "    y= df.columns,\n",
        "))\n",
        "fig.update_layout({\n",
        "    'title':\"stocks features Correlation Heatmap\"\n",
        "})\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "43h5pkJhqbjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_names = ['is_Monday', 'is_Tuesday', 'is_Wednesday', 'is_Thursday', 'is_Friday', 'is_Saturday', 'is_Sunday']\n",
        "\n",
        "for i, x in enumerate(day_names):\n",
        "    df[x] = df['Date'].dt.weekday.apply(lambda x: 1 if x == i else 0)"
      ],
      "metadata": {
        "id": "8-O9WgAdGuq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ZDDUCD-VMUF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_apple_full = df_apple_full.assign(apple_change=np.nan)"
      ],
      "metadata": {
        "id": "str9wvktJ9jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[-1]:\n",
        "#     df_apple_full.at[i,\"Volume_appl\"] = df_apple_full.at[i+1,\"Volume_appl\"]"
      ],
      "metadata": {
        "id": "4702Jz1tl_8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[-1]:\n",
        "#     df_apple_full.at[i,\"Volume_GSPC\"] = df_apple_full.at[i+1,\"Volume_GSPC\"]"
      ],
      "metadata": {
        "id": "ql0MQXMGkNyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[-1]:\n",
        "#     df_apple_full.at[i,\"apple_change\"] = df_apple_full.at[i+1,\"Adj Close_appl\"] - df_apple_full.at[i,\"Adj Close_appl\"]"
      ],
      "metadata": {
        "id": "TkzqJtfGj-to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[-1]:\n",
        "#     df_apple_full.at[i,\"apple_change_p\"] = abs(df_apple_full.at[i+1,\"Adj Close_appl\"] - df_apple_full.at[i,\"Adj Close_appl\"]) * 100 / df_apple_full.at[i,\"Adj Close_appl\"]\n",
        "#     if df_apple_full.at[i,\"apple_change\"] < 0: df_apple_full.at[i,\"apple_change_p\"]=df_apple_full.at[i,\"apple_change_p\"]* -1"
      ],
      "metadata": {
        "id": "6esReFGpOg8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[0]:\n",
        "#     df_apple_full.at[i,\"GSPC_change\"] = df_apple_full.at[i-1,\"Open_GSPC\"] - df_apple_full.at[i-1,\"Adj Close_GSPC\"]"
      ],
      "metadata": {
        "id": "uFaOK5FKI05M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[0]:\n",
        "#     df_apple_full.at[i,\"GSPC_change_p\"] = abs(df_apple_full.at[i-1,\"Open_GSPC\"] - df_apple_full.at[i-1,\"Adj Close_GSPC\"]) * 100 / df_apple_full.at[i,\"Open_GSPC\"]\n",
        "#     if df_apple_full.at[i,\"GSPC_change_p\"] < 0: df_apple_full.at[i,\"GSPC_change_p\"]=df_apple_full.at[i,\"GSPC_change_p\"]* -1"
      ],
      "metadata": {
        "id": "g2zF17qDJuF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[0]:\n",
        "#     df_apple_full.at[i,\"VIX_change\"] = df_apple_full.at[i-1,\"Open_VIX\"] - df_apple_full.at[i-1,\"Adj Close_VIX\"]"
      ],
      "metadata": {
        "id": "Gpy4P3ytLXKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in df_apple_full.iterrows():\n",
        "#   if i != df_apple_full.index[0]:\n",
        "#     df_apple_full.at[i,\"VIX_change_p\"] = abs(df_apple_full.at[i-1,\"Open_VIX\"] - df_apple_full.at[i-1,\"Adj Close_VIX\"]) * 100 / df_apple_full.at[i,\"Open_VIX\"]\n",
        "#     if df_apple_full.at[i,\"VIX_change_p\"] < 0: df_apple_full.at[i,\"VIX_change_p\"]=df_apple_full.at[i,\"VIX_change_p\"]* -1"
      ],
      "metadata": {
        "id": "MXTBMOMmLYPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df.iterrows():\n",
        "  if df.at[i,\"stock_change_target\"]\t>= 0:\n",
        "    df.at[i,\"target\"] = 1\n",
        "  if df.at[i,\"stock_change_target\"]\t< 0:\n",
        "    df.at[i,\"target\"] = 0\n",
        "  # if df_apple_full.at[i,\"apple_change_p\"]\t>= -0.5 and df_apple_full.at[i,\"apple_change_p\"]\t<= 0.5:\n",
        "  #   df_apple_full.at[i,\"target\"] = 0"
      ],
      "metadata": {
        "id": "tXiIvX1ZMd1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "njckTKZOrUGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_df = pd.get_dummies(df[\"company_name\"], prefix=\"company\")\n",
        "\n",
        "# concatenate the dummy variables with the original dataframe\n",
        "df = pd.concat([df, dummy_df], axis=1)\n",
        "\n",
        "# drop the original \"company_name\" column\n",
        "df.drop(\"company_name\", axis=1, inplace=True)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "6mMSPSQ5rk-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "Rq88otrAr6g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=df.columns[1:], axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "13zKZcsUsBtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "SDPAffKJsDWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OWNm_Nb2T_Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly7fMGYUVrr7"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_traces(go.Heatmap(\n",
        "    z=df.corr(),\n",
        "    x= df.columns,\n",
        "    y= df.columns,\n",
        "))\n",
        "fig.update_layout({\n",
        "    'title':\"stocks features Correlation Heatmap\"\n",
        "})\n",
        "\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = go.Figure()\n",
        "# fig.add_traces(go.Heatmap(\n",
        "#     z=df.corr(),\n",
        "#     x= df[\"stock_change_target\"],\n",
        "#     y= df.columns,\n",
        "# ))\n",
        "# fig.update_layout({\n",
        "#     'title':\"stocks features Correlation Heatmap\"\n",
        "# })\n",
        "\n",
        "\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "sT2BUZQfpvbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_apple_full.info"
      ],
      "metadata": {
        "id": "jTIed0pgPG-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CogqHXsFV_FQ"
      },
      "outputs": [],
      "source": [
        "df_data_for_models = df.drop(columns=['Volume','Open', 'Open_GSPC', 'High_GSPC' , 'Low_GSPC',  'High',    'Low',  'Close','Adj Close','Open',   'High',    'Low',  'Close_GSPC','Adj Close_GSPC','Open_VIX',   'High_VIX',    'Low_VIX',  'Close_VIX','Adj Close_VIX',])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models"
      ],
      "metadata": {
        "id": "YFwx8a2DlK1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models.info()"
      ],
      "metadata": {
        "id": "JBj0QIq0NdeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models = df_data_for_models.dropna()"
      ],
      "metadata": {
        "id": "ONIv6Fik6CBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_traces(go.Heatmap(\n",
        "    z=df_data_for_models.corr(),\n",
        "    x= df_data_for_models.columns,\n",
        "    y= df_data_for_models.columns,\n",
        "))\n",
        "fig.update_layout({\n",
        "    'title':\"Stocks features Correlation Heatmap\"\n",
        "})\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kZT64zbtP5aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_traces(go.Heatmap(\n",
        "    z=df_data_for_models.corr(),\n",
        "    x= df_data_for_models[\"target\"],\n",
        "    y= df_data_for_models.columns,\n",
        "))\n",
        "fig.update_layout({\n",
        "    'title':\"Stocks features Correlation Heatmap\"\n",
        "})\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ByP70cxIi2y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_data_for_models = df_apple_full.drop(columns=['Open_appl',   'High_appl',    'Low_appl',  'Close_appl','Adj Close_appl','Open_GSPC',   'High_GSPC',    'Low_GSPC',  'Close_GSPC','Adj Close_GSPC','Open_VIX',   'High_VIX',    'Low_VIX',  'Close_VIX','Adj Close_VIX'])"
      ],
      "metadata": {
        "id": "tQcN-tsJ3Qjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df_data_for_models.target.value_counts()\n",
        "counts"
      ],
      "metadata": {
        "id": "8uGaRZc2JzDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage = [str(round(i/counts.sum()*100,2)) + '%' for i in counts]\n",
        "percentage"
      ],
      "metadata": {
        "id": "Nf7OWUWDJy_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(\n",
        "    x=['rise', 'dwon'],\n",
        "    y=counts,\n",
        "    marker_color=['green','red'],\n",
        "    text=percentage,\n",
        "    textposition='outside',\n",
        "))\n",
        "fig.update_layout(\n",
        "    width=600,\n",
        "    title='percentage change',\n",
        "    yaxis_title='Number of days',\n",
        "    )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "1GdsufciJy8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "\n",
        "# df_data_for_models.loc[df_data_for_models['target'] == 1, 'target'] = 'Positive'\n",
        "# df_data_for_models.loc[df_data_for_models['target'] == 0, 'target'] = 'Negative'\n",
        "\n",
        "# df_grouped = df_data_for_models.groupby(['is_Monday', 'is_Tuesday', 'is_Wednesday', 'is_Thursday', 'is_Friday', 'target']).size().reset_index(name='counts')\n",
        "\n",
        "# days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
        "\n",
        "# fig, axs = plt.subplots(5, 1, figsize=(20, 20))\n",
        "# fig.suptitle('Target vs Day of Week')\n",
        "\n",
        "# for i, day in enumerate(days):\n",
        "#     axs[i].set_title(day)\n",
        "#     axs[i].set_xlabel('Target')\n",
        "#     axs[i].set_ylabel('Counts')\n",
        "#     day_df = df_grouped[df_grouped['is_'+day] == 1]\n",
        "#     axs[i].bar(day_df['target'], day_df['counts'])\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "PfY-eg9HxWS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# specify the columns you want to plot\n",
        "columns_to_plot = df_data_for_models.columns[2:25]\n",
        "\n",
        "# loop through each column and generate a histogram\n",
        "for column in columns_to_plot:\n",
        "    plt.hist(df_data_for_models[column])\n",
        "    plt.title(column)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZinHwexrzRGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [dict(label=x, values=df_data_for_models[x]) for x in df_data_for_models.columns if x != 'target']\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Splom(dimensions=dimensions))\n",
        "fig.update_traces(\n",
        "    marker=dict(color=df_data_for_models['target'],\n",
        "                size=5,\n",
        "                colorscale='Bluered',\n",
        "                line=dict(width=0.5,\n",
        "                color='rgb(230,230,230)')),\n",
        "    text=['Benign' if target==0 else 'Malignant' for target in df_data_for_models['target']],\n",
        "    diagonal=dict(visible=True)\n",
        ")\n",
        "fig.update_layout(\n",
        "    font=dict(\n",
        "        family=\"monospace\",\n",
        "        size=8,\n",
        "        color=\"RebeccaPurple\"\n",
        "    ),\n",
        "\n",
        "    height=800\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "PBSTV2iaJy4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "\n",
        "# df_data_for_models.loc[df_data_for_models['target'] == 1, 'target'] = 'Positive'\n",
        "# df_data_for_models.loc[df_data_for_models['target'] == 0, 'target'] = 'Negative'\n",
        "\n",
        "# df_grouped = df_data_for_models.groupby(['is_Monday', 'is_Tuesday', 'is_Wednesday', 'is_Thursday', 'is_Friday', 'target']).size().reset_index(name='counts')\n",
        "\n",
        "# days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
        "\n",
        "# fig, axs = plt.subplots(5, 1, figsize=(20, 20))\n",
        "# fig.suptitle('Target vs Day of Week')\n",
        "\n",
        "# for i, day in enumerate(days):\n",
        "#     axs[i].set_title(day)\n",
        "#     axs[i].set_xlabel('Target')\n",
        "#     axs[i].set_ylabel('Counts')\n",
        "#     day_df = df_grouped[df_grouped['is_'+day] == 1]\n",
        "#     axs[i].bar(day_df['target'], day_df['counts'])\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "z8s5N4w2K97s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_data_for_models.drop('target', axis=1)\n",
        "y = df_data_for_models.target"
      ],
      "metadata": {
        "id": "9kUtJmkXJyyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "cuaK-Pn6FXfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "wGOpqhivH1FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "model.fit(X,y)\n",
        "feat_importances_df = pd.DataFrame({'feature_importance':model.feature_importances_}, index=X.columns)\n",
        "feat_importances_df.sort_values(by='feature_importance', ascending=False)"
      ],
      "metadata": {
        "id": "3Tzw56CtLPre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models.head()"
      ],
      "metadata": {
        "id": "z6HV7Gb9fJAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import kruskal\n",
        "\n",
        "monday_group = df_data_for_models[df_data_for_models['is_Monday'] == 1]['target']\n",
        "tuesday_group = df_data_for_models[df_data_for_models['is_Tuesday'] == 1]['target']\n",
        "wednesday_group = df_data_for_models[df_data_for_models['is_Wednesday'] == 1]['target']\n",
        "thursday_group = df_data_for_models[df_data_for_models['is_Thursday'] == 1]['target']\n",
        "friday_group = df_data_for_models[df_data_for_models['is_Friday'] == 1]['target']\n",
        "\n",
        "stat, p = kruskal(monday_group, tuesday_group, wednesday_group, thursday_group, friday_group)\n",
        "print(f'Statistic: {stat}, p-value: {p}')"
      ],
      "metadata": {
        "id": "rUVqXdK8uIGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
        "\n",
        "for i, day in enumerate(days):\n",
        "    group = df_data_for_models[df_data_for_models[f'is_{day}'] == 1]['target'].value_counts().values\n",
        "    stat, p, dof, expected = chi2_contingency([group])\n",
        "    print(f'{day}: Statistic={stat:.4f}, p-value={p:.4f}')\n"
      ],
      "metadata": {
        "id": "lHgdw-nlkZ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monday_group = df_data_for_models[df_data_for_models['is_Tuesday'] == 1]['target']\n",
        "non_monday_group = df_data_for_models[df_data_for_models['is_Tuesday'] == 0]['target']\n",
        "\n",
        "stat, p = kruskal(monday_group, non_monday_group)\n",
        "print(f'Statistic: {stat}, p-value: {p}')"
      ],
      "metadata": {
        "id": "6EBMcCiRupEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monday_group = df_data_for_models[df_data_for_models['is_Wednesday'] == 1]['target']\n",
        "non_monday_group = df_data_for_models[df_data_for_models['is_Wednesday'] == 0]['target']\n",
        "\n",
        "stat, p = kruskal(monday_group, non_monday_group)\n",
        "print(f'Statistic: {stat}, p-value: {p}')"
      ],
      "metadata": {
        "id": "ohWQo7GFwiFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monday_group = df_data_for_models[df_data_for_models['is_Thursday'] == 1]['target']\n",
        "non_monday_group = df_data_for_models[df_data_for_models['is_Thursday'] == 0]['target']\n",
        "\n",
        "stat, p = kruskal(monday_group, non_monday_group)\n",
        "print(f'Statistic: {stat}, p-value: {p}')"
      ],
      "metadata": {
        "id": "1JuVbD4dwh9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monday_group = df_data_for_models[df_data_for_models['is_Friday'] == 1]['target']\n",
        "non_monday_group = df_data_for_models[df_data_for_models['is_Friday'] == 0]['target']\n",
        "\n",
        "stat, p = kruskal(monday_group, non_monday_group)\n",
        "print(f'Statistic: {stat}, p-value: {p}')"
      ],
      "metadata": {
        "id": "1OwIoI0Awh1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monday_group = df_data_for_models[df_data_for_models['is_Monday'] == 1]['target']\n",
        "non_monday_group = df_data_for_models[df_data_for_models['is_Monday'] == 0]['target']\n",
        "\n",
        "stat, p = kruskal(monday_group, non_monday_group)\n",
        "print(f'Statistic: {stat}, p-value: {p}')"
      ],
      "metadata": {
        "id": "3kdXoCY0wfNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest , chi2\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "chi_selector = SelectKBest(chi2, k =len(X.columns))\n",
        "chi_selector.fit(X_scaled, y)\n",
        "\n",
        "# chi_selector = SelectKBest(chi2, k =len(X.columns))\n",
        "# chi_selector.fit(X, y)\n",
        "\n",
        "scores = pd.Series(chi_selector.scores_.tolist())\n",
        "p_values = round(pd.Series(chi_selector.pvalues_.tolist()), 4)\n",
        "selected_df = pd.DataFrame({'univariate_score':scores, 'p_values':p_values})\n",
        "selected_df.set_index(X.columns, inplace=True, drop=True)\n",
        "univariate = selected_df.sort_values(by='univariate_score', ascending=False)\n",
        "univariate"
      ],
      "metadata": {
        "id": "H5HYCYBuLPio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STATS"
      ],
      "metadata": {
        "id": "laTZm9SXV15a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models"
      ],
      "metadata": {
        "id": "3ih50wqKVz4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models.info()"
      ],
      "metadata": {
        "id": "8EnPacaqvCkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"target\"].head()"
      ],
      "metadata": {
        "id": "btxNhP-XBN1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ranksums\n",
        "\n",
        "columns = ['GSPC_change_in_day_Adj', 'GSPC_change_in_day', 'GSPC_change_in_day_open_high',\n",
        "           'GSPC_change_in_day_open_low', 'GSPC_change_in_day_high_low', 'VIX_change_in_day_Adj',\n",
        "           'VIX_change_in_day', 'VIX_change_in_day_open_high', 'VIX_change_in_day_open_low',\n",
        "           'VIX_change_in_day_high_low', 'stock_change_target', 'stock_change_in_day_Adj',\n",
        "           'stock_change_in_day', 'stock_change_in_day_open_high', 'stock_change_in_day_open_low',\n",
        "           'stock_change_in_day_high_low', 'stock_MA_for_10_days', 'stock_MA_for_20_days',\n",
        "           'stock_MA_for_50_days', 'GSPC_MA_for_10_days', 'GSPC_MA_for_20_days', 'GSPC_MA_for_50_days',\n",
        "           'VIX_MA_for_50_days']\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "\n",
        "for col in columns:\n",
        "    x = df_data_for_models[col]\n",
        "    y = df_data_for_models[\"target\"]\n",
        "    statistic, p_value = ranksums(x, y)\n",
        "    print(f\"Wilcoxon rank-sum test on {col}:\")\n",
        "    print(f\"Statistic: {statistic:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "LTuNgPoQmima"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "x = df_data_for_models[\"stock_MA_for_10_days\"]\n",
        "y = df_data_for_models[\"target\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "Y1scA2_eYm38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "# Get a list of all unique categories in df_data_for_models[\"target\"]\n",
        "categories = df_data_for_models[\"target\"].unique()\n",
        "\n",
        "# Perform pairwise Wilcoxon rank-sum tests between each pair of categories\n",
        "for cat1, cat2 in combinations(categories, 2):\n",
        "    x = df_data_for_models.loc[df_data_for_models[\"target\"] == cat1, \"stock_MA_for_10_days\"]\n",
        "    y = df_data_for_models.loc[df_data_for_models[\"target\"] == cat2, \"stock_MA_for_10_days\"]\n",
        "    statistic, p_value = ranksums(x, y)\n",
        "    print(f\"Pairwise test between {cat1} and {cat2}:\")\n",
        "    print(f\"Statistic: {statistic:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n"
      ],
      "metadata": {
        "id": "1Gqo5QoEmD92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "for cat1, cat2 in combinations(categories, 2):\n",
        "    x = df_data_for_models.loc[df_data_for_models[\"target\"] == cat1, \"stock_MA_for_20_days\"]\n",
        "    y = df_data_for_models.loc[df_data_for_models[\"target\"] == cat2, \"stock_MA_for_20_days\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "xs8PSb5daTX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "for cat1, cat2 in combinations(categories, 2):\n",
        "    x = df_data_for_models.loc[df_data_for_models[\"target\"] == cat1, \"stock_MA_for_50_days\"]\n",
        "    y = df_data_for_models.loc[df_data_for_models[\"target\"] == cat2, \"stock_MA_for_50_days\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "4FzPnPP6aWsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "for cat1, cat2 in combinations(categories, 2):\n",
        "    x = df_data_for_models.loc[df_data_for_models[\"target\"] == cat1, \"Volume_GSPC\"]\n",
        "    y = df_data_for_models.loc[df_data_for_models[\"target\"] == cat2, \"Volume_GSPC\"]\n",
        "\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "2kC30SXEaZ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "for cat1, cat2 in combinations(categories, 2):\n",
        "    x = df_data_for_models.loc[df_data_for_models[\"target\"] == cat1, \"GSPC_change_in_day_Adj\"]\n",
        "    y = df_data_for_models.loc[df_data_for_models[\"target\"] == cat2, \"GSPC_change_in_day_Adj\"]\n",
        "\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "Ree0IlyHaZia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models[\"target\"].head()"
      ],
      "metadata": {
        "id": "ELVwRrUbCKX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "x = df_data_for_models[\"GSPC_MA_for_10_days\"]\n",
        "y = df_data_for_models[\"target\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "NbzpvLT1aZfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "x = df_data_for_models[\"GSPC_MA_for_20_days\"]\n",
        "y = df_data_for_models[\"target\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "-82ysCaUaZc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "x = df_data_for_models[\"GSPC_MA_for_50_days\"]\n",
        "y = df_data_for_models[\"target\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "3THq5q1zaZPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "x = df_data_for_models[\"VIX_change_in_day_Adj\"]\n",
        "y = df_data_for_models[\"target\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "wupO4HFKemUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "# Extract the variables from the data frames\n",
        "x = df_data_for_models[\"VIX_MA_for_50_days\"]\n",
        "y = df_data_for_models[\"target\"]\n",
        "\n",
        "# Perform the Wilcoxon rank-sum test\n",
        "statistic, p_value = ranksums(x, y)\n",
        "\n",
        "# Print the results\n",
        "print(\"Wilcoxon rank-sum test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "82YZ4ynkelRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STATS END"
      ],
      "metadata": {
        "id": "s2aTNxXpV2St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled= df_data_for_models.drop(columns=['Date','target','stock_change_target'])\n",
        "y = df_data_for_models['target']"
      ],
      "metadata": {
        "id": "P8xUigXbQKwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1234)\n",
        "train_df = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
        "test_df = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "isGLfvZg3jOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "g9pokXhT4WqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# encoding train labels\n",
        "encoder.fit(y_train)\n",
        "y_train_n = encoder.transform(y_train)\n",
        "\n",
        "# encoding test labels\n",
        "encoder.fit(y_test)\n",
        "y_test_n = encoder.transform(y_test)\n",
        "print(y_test[0:5].to_list())\n",
        "print(y_test_n[0:5])"
      ],
      "metadata": {
        "id": "0BVJRxEr4CFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "tVCrF4i6ONIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.info()"
      ],
      "metadata": {
        "id": "9Q_QSHGlNKQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import svm"
      ],
      "metadata": {
        "id": "dEJwFQR13k4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linearCls = svm.SVC().set_params(kernel='linear')\n",
        "# polyCls = svm.SVC().set_params(kernel='poly')\n",
        "# rbfCls = svm.SVC().set_params(kernel='rbf')"
      ],
      "metadata": {
        "id": "zqwAj7WZ30Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linearCls.fit(X_train, y_train_n)"
      ],
      "metadata": {
        "id": "X5McvSo332Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# polyCls.fit(X_train, y_train_n)"
      ],
      "metadata": {
        "id": "G-TIJkeObNRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rbfCls.fit(X_train, y_train_n)"
      ],
      "metadata": {
        "id": "lgh9vbO7bOdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_data_for_models.drop(columns=['Date','target','stock_change_target'])\n",
        "y = df_data_for_models['target']"
      ],
      "metadata": {
        "id": "qf072Y6hPR7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "7y4rpeKzQQho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "train_df = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
        "test_df = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
        "train_df.head(5)"
      ],
      "metadata": {
        "id": "wtBIsr3OPOV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "iDm5tlQsRxcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 1)"
      ],
      "metadata": {
        "id": "ih_QhKfxR2rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "NE6p-bnOR5_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = knn.predict(X_train)"
      ],
      "metadata": {
        "id": "O9BkqqHLR7uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = pd.Series(prediction, name='prediction', index=y_train.index)\n",
        "\n",
        "train_results = pd.DataFrame(data={'prediction':y_train_pred, 'actual':y_train})\n",
        "train_results"
      ],
      "metadata": {
        "id": "Ki_khK5LR9yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_correct_rows = len(train_results.loc[train_results.prediction==train_results.actual])\n",
        "accuracy = round(len_correct_rows/len(train_results),3)\n",
        "print('accuracy = ', accuracy)\n",
        "\n",
        "from sklearn import metrics\n",
        "accu = metrics.accuracy_score(y_train, y_train_pred)\n",
        "accu"
      ],
      "metadata": {
        "id": "tEP9A8t0R_6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "y_test_pred = pd.Series(y_pred, name='prediction', index=y_test.index)\n",
        "\n",
        "test_results = pd.DataFrame(data={'prediction':y_test_pred, 'actual':y_test})\n",
        "test_results"
      ],
      "metadata": {
        "id": "ecbEt4HQSDdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "xx9urFDKSI4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(confusion)"
      ],
      "metadata": {
        "id": "3MkF07lySLXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion, display_labels=knn.classes_)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "LT7c1K1_SNbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "iZVLtIX0SQM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "error_rate = []\n",
        "for i in range(1,200):\n",
        "    knn = KNeighborsClassifier(n_neighbors = i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error_rate.append(np.mean(pred_i != y_test))"
      ],
      "metadata": {
        "id": "tQriHd1xSRZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trace = go.Scatter(\n",
        "    x=[i for i in range(1,200)],\n",
        "    y=error_rate,\n",
        "    mode='markers+lines',\n",
        ")\n",
        "fig = go.Figure(trace)\n",
        "fig.update_layout(\n",
        "    title='Error by K Value',\n",
        "    xaxis_title='k neighboors',\n",
        "    yaxis_title='Error rate'\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "LglEK94VSUJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(X_train, y_train)\n",
        "pred_train = knn.predict(X_train)\n",
        "print(metrics.accuracy_score(y_train, pred_train))\n",
        "\n",
        "print('===========================================')\n",
        "\n",
        "pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "print(knn.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "F4c5Ea5mq6Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "knn = KNeighborsClassifier(n_neighbors = 7)\n",
        "knn.fit(X_train, y_train)\n",
        "pred_train = knn.predict(X_train)\n",
        "print(metrics.accuracy_score(y_train, pred_train))\n",
        "\n",
        "print('===========================================')\n",
        "\n",
        "pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "print(knn.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "WetKi_-brAyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "knn = KNeighborsClassifier(n_neighbors = 13)\n",
        "knn.fit(X_train, y_train)\n",
        "pred_train = knn.predict(X_train)\n",
        "print(metrics.accuracy_score(y_train, pred_train))\n",
        "\n",
        "print('===========================================')\n",
        "\n",
        "pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "print(knn.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "6-6Y2X63hxHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "knn = KNeighborsClassifier(n_neighbors = 30)\n",
        "knn.fit(X_train, y_train)\n",
        "pred_train = knn.predict(X_train)\n",
        "print(metrics.accuracy_score(y_train, pred_train))\n",
        "\n",
        "print('===========================================')\n",
        "\n",
        "pred = knn.predict(X_test)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "print(knn.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "yw1fRLZk-M5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=30,criterion='entropy')"
      ],
      "metadata": {
        "id": "NbG8kFvOCRkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "TUWnbOZhCUhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "4cX-tHcCCW2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,y_predict))\n",
        "print('----------------------------------------------------------')\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "metadata": {
        "id": "bssqmX10CX99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "auc_scores = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\n",
        "auc_scores"
      ],
      "metadata": {
        "id": "K8DA-gLGCZYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = cross_val_score(rfc, X, y, cv=10, scoring='accuracy')\n",
        "accuracy_scores"
      ],
      "metadata": {
        "id": "uHnf6k5hCa0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean values')\n",
        "print('auc:', auc_scores.mean())\n",
        "print('accuracy: ', accuracy_scores.mean())\n"
      ],
      "metadata": {
        "id": "Q_1ZTmSWCbwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TZQjvie2eWsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['predicted_y'] = rfc.predict(X_train)\n",
        "test_df['predicted_y'] = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "hsTKE0gDeYQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new dataframes with train and test data\n",
        "df_rf_s_train = pd.concat([df_data_for_models, pd.DataFrame(rfc.predict(X_train), index=X_train.index, columns=['predicted_y'])], axis=1)\n",
        "df_rf_s_test = pd.concat([test_df, pd.DataFrame(rfc.predict(X_test), index=X_test.index, columns=['predicted_y'])], axis=1)\n"
      ],
      "metadata": {
        "id": "6jXZSC-cijb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge training and test dataframes with predictions\n",
        "df_rf_s = pd.concat([df_data_for_models,\n",
        "                     train_df[['predicted_y']].rename(columns={'predicted_y':'predicted_y'}),\n",
        "                     test_df[['predicted_y']].rename(columns={'predicted_y':'predicted_y'})],\n",
        "                    axis=1)\n"
      ],
      "metadata": {
        "id": "EkzISPoWmy6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rf_s"
      ],
      "metadata": {
        "id": "2vjTPCMUm1b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_for_models.info()"
      ],
      "metadata": {
        "id": "kHhROgAMiGn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8LnkwDKmeWWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "dcmfF7g0C0fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "ZL-oS9HJC1yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability = logmodel.predict_proba(X_train)\n",
        "prediction = logmodel.predict(X_train)\n",
        "prediction"
      ],
      "metadata": {
        "id": "upHpF0uhC1pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_prob_0 = pd.Series(probability[:,0], name ='probability_0', index=y_train.index)\n",
        "y_train_prob_1 = pd.Series(probability[:,1], name ='probability_1', index=y_train.index)\n",
        "y_train_pred   = pd.Series(prediction      , name ='prediction'   , index=y_train.index)\n",
        "\n",
        "train_results = pd.DataFrame(data={'probability_0':y_train_prob_0, 'probability_1':y_train_prob_1,'prediction':y_train_pred, 'actual':y_train})\n",
        "train_results"
      ],
      "metadata": {
        "id": "eb_owRYVC1cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_rows = len(train_results.loc[train_results.prediction == train_results.actual])\n",
        "correct_rows"
      ],
      "metadata": {
        "id": "zwaEUQnuDS8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = round(correct_rows/len(train_results),2)\n",
        "print(str(accuracy) + '%')"
      ],
      "metadata": {
        "id": "nXQKupfOJHMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print('----------------------------------------------------------')\n",
        "print(classification_report(y_test,y_predict))\n"
      ],
      "metadata": {
        "id": "P1921QDKpgx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability = logmodel.predict_proba(X_test)\n",
        "prediction = logmodel.predict(X_test)"
      ],
      "metadata": {
        "id": "eIbWg0XtJKAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_prob_0 =pd.Series(probability[:,0], name='probability_0', index=y_test.index)\n",
        "y_test_prob_1 =pd.Series(probability[:,1], name='probability_1', index=y_test.index)\n",
        "y_test_pred = pd.Series(prediction, name='prediction', index=y_test.index)\n",
        "\n",
        "test_results = pd.DataFrame(data={'probability_0':y_test_prob_0, 'probability_1':y_test_prob_1,'prediction':y_test_pred, 'actual':y_test})\n",
        "test_results"
      ],
      "metadata": {
        "id": "562OOxt7JLl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = round(correct_rows/len(test_results),2)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "GXU-Qj46JOWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "clf = SVC()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "print(confusion_matrix(y_test,y_predict))\n",
        "print('----------------------------------------------------------')\n",
        "print(classification_report(y_test,y_predict))\n"
      ],
      "metadata": {
        "id": "QGB2WXf3Peq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# trained_rf is your trained random forest model\n",
        "with open('random_forest_model.pkl', 'wb') as f:\n",
        "    pickle.dump(rfc, f)"
      ],
      "metadata": {
        "id": "Ti-MxgSOVoOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X70iy4Iajzsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('random_forest_model.pkl')"
      ],
      "metadata": {
        "id": "VBC5ZYWkj5s8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}